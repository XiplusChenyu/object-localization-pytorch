{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Q Model\n",
    "## Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FileUtils import FileUtils\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to load data\n",
      "Start to load images: 1000=>2000=>3000=>4000=>5000=>6000=>7000=>8000=>9000=>10000=>11000=>11540!\n",
      "Start to load annotations: 1000=>2000=>3000=>4000=>5000=>6000=>7000=>8000=>9000=>10000=>11000=>11540!\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "data = FileUtils()\n",
    "data.filter_by_class(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1084"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.images) # the length of the cat images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import QModel\n",
    "from Settings import Settings\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if Settings.cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QModel(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=25112, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.6, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.6, inplace=False)\n",
       "    (6): Linear(in_features=1024, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model = QModel()\n",
    "# target_model = QModel()\n",
    "# target_model.load_state_dict(policy_model.state_dict())\n",
    "\n",
    "policy_model.cuda()\n",
    "# target_model.cuda()\n",
    "# target_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReplayMemory import ReplayMemory\n",
    "memory = ReplayMemory(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.RMSprop(policy_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from Agent import Agent\n",
    "from IoU import *\n",
    "from TrainUtils import optimize_model\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 100\n",
    "eps = Settings.eps_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Settings.target_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Model Training\n",
      "==> Epoch 0 start ...\n",
      "==> Epoch 0 End, time cost = 43.1303, current loss = 1.1126, next eps = 0.8\n",
      "==> Epoch 1 start ...\n",
      "==> Epoch 1 End, time cost = 42.5094, current loss = 1.0462, next eps = 0.7\n",
      "==> Epoch 2 start ...\n",
      "==> Epoch 2 End, time cost = 46.4034, current loss = 1.2321, next eps = 0.6\n",
      "==> Epoch 3 start ...\n",
      "==> Epoch 3 End, time cost = 48.9088, current loss = 1.0535, next eps = 0.5\n",
      "==> Epoch 4 start ...\n",
      "==> Epoch 4 End, time cost = 51.1008, current loss = 0.9564, next eps = 0.4\n",
      "==> Epoch 5 start ...\n",
      "==> Epoch 5 End, time cost = 53.0756, current loss = 0.9969, next eps = 0.3\n",
      "==> Epoch 6 start ...\n",
      "==> Epoch 6 End, time cost = 56.1601, current loss = 1.1822, next eps = 0.2\n",
      "==> Epoch 7 start ...\n",
      "==> Epoch 7 End, time cost = 59.3011, current loss = 0.8611, next eps = 0.1\n",
      "==> Epoch 8 start ...\n",
      "==> Epoch 8 End, time cost = 60.4335, current loss = 1.1087, next eps = 0.1\n",
      "==> Epoch 9 start ...\n",
      "==> Epoch 9 End, time cost = 61.2564, current loss = 1.252, next eps = 0.1\n",
      "==> Epoch 10 start ...\n",
      "==> Epoch 10 End, time cost = 61.4511, current loss = 0.9848, next eps = 0.1\n",
      "==> Epoch 11 start ...\n",
      "==> Epoch 11 End, time cost = 61.3894, current loss = 1.0791, next eps = 0.1\n",
      "==> Epoch 12 start ...\n",
      "==> Epoch 12 End, time cost = 60.0072, current loss = 1.2159, next eps = 0.1\n",
      "==> Epoch 13 start ...\n",
      "==> Epoch 13 End, time cost = 59.382, current loss = 1.2016, next eps = 0.1\n",
      "==> Epoch 14 start ...\n",
      "==> Epoch 14 End, time cost = 60.4172, current loss = 0.819, next eps = 0.1\n",
      "==> Epoch 15 start ...\n",
      "==> Epoch 15 End, time cost = 61.0292, current loss = 0.7451, next eps = 0.1\n",
      "==> Epoch 16 start ...\n",
      "==> Epoch 16 End, time cost = 59.2428, current loss = 1.0028, next eps = 0.1\n",
      "==> Epoch 17 start ...\n",
      "==> Epoch 17 End, time cost = 59.7627, current loss = 1.1197, next eps = 0.1\n",
      "==> Epoch 18 start ...\n",
      "==> Epoch 18 End, time cost = 59.7805, current loss = 0.9694, next eps = 0.1\n",
      "==> Epoch 19 start ...\n",
      "==> Epoch 21 End, time cost = 61.8507, current loss = 0.8586, next eps = 0.1\n",
      "==> Epoch 22 start ...\n",
      "==> Epoch 22 End, time cost = 60.0583, current loss = 0.8694, next eps = 0.1\n",
      "==> Epoch 23 start ...\n",
      "==> Epoch 23 End, time cost = 60.9213, current loss = 0.8813, next eps = 0.1\n",
      "==> Epoch 24 start ...\n",
      "==> Epoch 24 End, time cost = 60.3749, current loss = 0.96, next eps = 0.1\n",
      "==> Epoch 25 start ...\n",
      "==> Epoch 25 End, time cost = 60.2204, current loss = 1.0314, next eps = 0.1\n",
      "==> Epoch 26 start ...\n",
      "==> Epoch 26 End, time cost = 60.9751, current loss = 1.124, next eps = 0.1\n",
      "==> Epoch 27 start ...\n",
      "==> Epoch 27 End, time cost = 59.2705, current loss = 0.9544, next eps = 0.1\n",
      "==> Epoch 28 start ...\n",
      "==> Epoch 28 End, time cost = 60.157, current loss = 1.0572, next eps = 0.1\n",
      "==> Epoch 29 start ...\n",
      "==> Epoch 29 End, time cost = 59.6303, current loss = 1.1593, next eps = 0.1\n",
      "==> Epoch 30 start ...\n",
      "==> Epoch 30 End, time cost = 59.8293, current loss = 1.0457, next eps = 0.1\n",
      "==> Epoch 31 start ...\n",
      "==> Epoch 31 End, time cost = 61.3119, current loss = 1.3109, next eps = 0.1\n",
      "==> Epoch 32 start ...\n",
      "==> Epoch 32 End, time cost = 59.5166, current loss = 0.9706, next eps = 0.1\n",
      "==> Epoch 33 start ...\n",
      "==> Epoch 33 End, time cost = 60.3344, current loss = 1.0201, next eps = 0.1\n",
      "==> Epoch 34 start ...\n",
      "==> Epoch 34 End, time cost = 61.3879, current loss = 0.9148, next eps = 0.1\n",
      "==> Epoch 35 start ...\n",
      "==> Epoch 35 End, time cost = 60.2475, current loss = 1.0963, next eps = 0.1\n",
      "==> Epoch 36 start ...\n",
      "==> Epoch 36 End, time cost = 59.931, current loss = 1.0929, next eps = 0.1\n",
      "==> Epoch 37 start ...\n",
      "==> Epoch 37 End, time cost = 61.5353, current loss = 1.0745, next eps = 0.1\n",
      "==> Epoch 38 start ...\n",
      "==> Epoch 38 End, time cost = 60.3404, current loss = 0.9041, next eps = 0.1\n",
      "==> Epoch 39 start ...\n",
      "==> Epoch 39 End, time cost = 60.1221, current loss = 1.165, next eps = 0.1\n",
      "==> Epoch 40 start ...\n",
      "==> Epoch 40 End, time cost = 60.2464, current loss = 0.9776, next eps = 0.1\n",
      "==> Epoch 41 start ...\n",
      "==> Epoch 41 End, time cost = 60.2671, current loss = 1.242, next eps = 0.1\n",
      "==> Epoch 42 start ...\n",
      "==> Epoch 42 End, time cost = 60.4872, current loss = 0.9855, next eps = 0.1\n",
      "==> Epoch 43 start ...\n",
      "==> Epoch 43 End, time cost = 59.7439, current loss = 0.7502, next eps = 0.1\n",
      "==> Epoch 44 start ...\n",
      "==> Epoch 44 End, time cost = 61.1635, current loss = 0.8331, next eps = 0.1\n",
      "==> Epoch 45 start ...\n",
      "==> Epoch 45 End, time cost = 61.8245, current loss = 0.9325, next eps = 0.1\n",
      "==> Epoch 46 start ...\n",
      "==> Epoch 46 End, time cost = 61.1357, current loss = 0.8121, next eps = 0.1\n",
      "==> Epoch 47 start ...\n",
      "==> Epoch 47 End, time cost = 60.9948, current loss = 0.8586, next eps = 0.1\n",
      "==> Epoch 48 start ...\n",
      "==> Epoch 48 End, time cost = 60.1078, current loss = 1.1133, next eps = 0.1\n",
      "==> Epoch 49 start ...\n",
      "==> Epoch 49 End, time cost = 60.5319, current loss = 1.0784, next eps = 0.1\n",
      "==> Epoch 50 start ...\n",
      "==> Epoch 50 End, time cost = 61.0083, current loss = 0.8769, next eps = 0.1\n",
      "==> Epoch 51 start ...\n",
      "==> Epoch 51 End, time cost = 58.9987, current loss = 0.9899, next eps = 0.1\n",
      "==> Epoch 52 start ...\n",
      "==> Epoch 52 End, time cost = 61.4862, current loss = 0.9389, next eps = 0.1\n",
      "==> Epoch 53 start ...\n",
      "==> Epoch 53 End, time cost = 60.2513, current loss = 1.0947, next eps = 0.1\n",
      "==> Epoch 54 start ...\n",
      "==> Epoch 54 End, time cost = 60.425, current loss = 1.013, next eps = 0.1\n",
      "==> Epoch 55 start ...\n",
      "==> Epoch 55 End, time cost = 61.2656, current loss = 1.04, next eps = 0.1\n",
      "==> Epoch 56 start ...\n",
      "==> Epoch 56 End, time cost = 61.0407, current loss = 1.0511, next eps = 0.1\n",
      "==> Epoch 57 start ...\n",
      "==> Epoch 57 End, time cost = 61.1177, current loss = 0.9054, next eps = 0.1\n",
      "==> Epoch 58 start ...\n",
      "==> Epoch 58 End, time cost = 60.649, current loss = 0.9799, next eps = 0.1\n",
      "==> Epoch 59 start ...\n",
      "==> Epoch 59 End, time cost = 60.9033, current loss = 1.1068, next eps = 0.1\n",
      "==> Epoch 60 start ...\n",
      "==> Epoch 60 End, time cost = 61.8355, current loss = 0.8369, next eps = 0.1\n",
      "==> Epoch 61 start ...\n",
      "==> Epoch 61 End, time cost = 59.61, current loss = 0.8797, next eps = 0.1\n",
      "==> Epoch 62 start ...\n",
      "==> Epoch 62 End, time cost = 61.968, current loss = 0.8975, next eps = 0.1\n",
      "==> Epoch 63 start ...\n",
      "==> Epoch 63 End, time cost = 60.086, current loss = 0.976, next eps = 0.1\n",
      "==> Epoch 64 start ...\n",
      "==> Epoch 64 End, time cost = 61.92, current loss = 0.8815, next eps = 0.1\n",
      "==> Epoch 65 start ...\n",
      "==> Epoch 65 End, time cost = 60.3181, current loss = 0.9891, next eps = 0.1\n",
      "==> Epoch 66 start ...\n",
      "==> Epoch 66 End, time cost = 59.6243, current loss = 1.0061, next eps = 0.1\n",
      "==> Epoch 67 start ...\n",
      "==> Epoch 67 End, time cost = 59.2194, current loss = 0.7655, next eps = 0.1\n",
      "==> Epoch 68 start ...\n",
      "==> Epoch 68 End, time cost = 59.9017, current loss = 0.8082, next eps = 0.1\n",
      "==> Epoch 69 start ...\n",
      "==> Epoch 69 End, time cost = 60.9894, current loss = 1.0263, next eps = 0.1\n",
      "==> Epoch 70 start ...\n",
      "==> Epoch 70 End, time cost = 59.7247, current loss = 0.9198, next eps = 0.1\n",
      "==> Epoch 71 start ...\n",
      "==> Epoch 71 End, time cost = 59.69, current loss = 1.1405, next eps = 0.1\n",
      "==> Epoch 72 start ...\n",
      "==> Epoch 72 End, time cost = 60.6343, current loss = 1.0688, next eps = 0.1\n",
      "==> Epoch 73 start ...\n",
      "==> Epoch 73 End, time cost = 61.8777, current loss = 0.9163, next eps = 0.1\n",
      "==> Epoch 74 start ...\n",
      "==> Epoch 74 End, time cost = 61.388, current loss = 1.3225, next eps = 0.1\n",
      "==> Epoch 75 start ...\n",
      "==> Epoch 75 End, time cost = 58.6453, current loss = 0.9254, next eps = 0.1\n",
      "==> Epoch 76 start ...\n",
      "==> Epoch 76 End, time cost = 60.9859, current loss = 1.0684, next eps = 0.1\n",
      "==> Epoch 77 start ...\n",
      "==> Epoch 77 End, time cost = 59.1927, current loss = 1.0506, next eps = 0.1\n",
      "==> Epoch 78 start ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d095588254ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cv/Scripts/Agent.py\u001b[0m in \u001b[0;36mget_next_action\u001b[0;34m(self, q_model, eps)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cv/Scripts/Agent.py\u001b[0m in \u001b[0;36mget_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mimage_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mhistory_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cv/Scripts/Models.py\u001b[0m in \u001b[0;36mget_image_feature\u001b[0;34m(im, model)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mfeature_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# no need to record\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         return F.batch_norm(\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             exponential_average_factor, self.eps)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Start Model Training\")\n",
    "loss_list = list()\n",
    "for epoch in range(epoch_num):\n",
    "    print(\"==> Epoch {} start ...\".format(epoch))\n",
    "    start = time.time()\n",
    "    cur_loss = 0.0\n",
    "    \n",
    "    for i, image in enumerate(data.images[:1000]):\n",
    "        annotation_list = data.annotations[i]\n",
    "        agent = Agent(image)\n",
    "        done = False\n",
    "        old_iou_list = None\n",
    "        cur_state = None\n",
    "        \n",
    "        for step in range(Settings.max_step):\n",
    "            \n",
    "            iou_list = [iou_calculator(agent.boundary, x) for x in annotation_list]\n",
    "            max_index = max(range(len(iou_list)), key=lambda x: iou_list[x])\n",
    "            iou = max(iou_list)\n",
    "            old_iou = old_iou_list[max_index] if old_iou_list else 0\n",
    "            old_iou_list = iou_list\n",
    "            \n",
    "            cur_state = agent.get_state() if step == 0 else cur_state # current state\n",
    "            \n",
    "            # determine if we should end the result \n",
    "            if iou > Settings.iou_threshold:\n",
    "                action = torch.tensor(6).to(device)\n",
    "            else:\n",
    "                action = agent.get_next_action(policy_model, eps)\n",
    "\n",
    "            if action == 6:\n",
    "                reward = reward_terminal(iou)\n",
    "                done = True\n",
    "                next_state = None\n",
    "            else:\n",
    "                agent.hierarchical_move(action)\n",
    "                agent.update_history_vector(action)\n",
    "                if agent.sub_image.shape[0] * agent.sub_image.shape[1] == 0:\n",
    "                    done = True\n",
    "                    next_state = None\n",
    "                else:\n",
    "                    next_state = agent.get_state()\n",
    "                    reward = reward_move(old_iou, iou)\n",
    "            \n",
    "            \n",
    "            memory.push(cur_state, action, next_state, reward)\n",
    "            cur_state = next_state\n",
    "            \n",
    "#             cur_loss = optimize_model(policy_model, target_model, memory, optimizer)\n",
    "            cur_loss = optimize_model(policy_model, memory, optimizer)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "#     if epoch % 1 == 0:\n",
    "#         print(\"Update Network\")\n",
    "#         target_model.load_state_dict(policy_model.state_dict())\n",
    "    loss_list.append(cur_loss)\n",
    "\n",
    "    # save logs\n",
    "    with open(\"{}log.json\".format(Settings.model_path), \"w\") as f:\n",
    "        json.dump(loss_list, f)\n",
    "\n",
    "    with open(\"{}model{}.pt\".format(Settings.model_path, epoch), 'wb') as f:\n",
    "            torch.save(policy_model.cpu().state_dict(), f)\n",
    "            if Settings.cuda:\n",
    "                policy_model.cuda()\n",
    "\n",
    "#     target_model.eval()\n",
    "        \n",
    "    if eps > 0.11:\n",
    "        eps -= 0.1\n",
    "    else:\n",
    "        eps = 0.1\n",
    "    \n",
    "    time_cost = time.time() - start\n",
    "    print(\"==> Epoch {} End, time cost = {}, current loss = {}, next eps = {}\".format(epoch, round(time_cost,4), cur_loss, round(eps,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModelOnOneImage(image_index):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data.images[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Image import Image\n",
    "image = Image(data, 49)\n",
    "annotation_list = image.objects\n",
    "agent = Agent(image.image)\n",
    "done = False\n",
    "\n",
    "for step in range(Settings.max_step):\n",
    "    print(\"Step {}\".format(step), end=\"=>\")\n",
    "    \n",
    "    iou_list = [iou_calculator(agent.boundary, x) for x in annotation_list]\n",
    "    max_index = max(range(len(iou_list)), key=lambda x: iou_list[x])\n",
    "    iou = max(iou_list)\n",
    "    \n",
    "    print(\"current iou = {}\".format(iou), end=\" || \")\n",
    "    old_iou = old_iou_list[max_index] if old_iou_list else 0\n",
    "    old_iou_list = iou_list\n",
    "\n",
    "    cur_state = agent.get_state()\n",
    "\n",
    "    # determine if we should end the result \n",
    "    if iou > Settings.iou_threshold:\n",
    "        action = torch.tensor(6).to(device)\n",
    "    else:\n",
    "        action = agent.get_next_action(policy_model, eps=0)\n",
    "\n",
    "    if action == 6:\n",
    "        reward = reward_terminal(iou)\n",
    "        done = True\n",
    "        next_state = None\n",
    "    else:\n",
    "        agent.hierarchical_move(action)\n",
    "        agent.update_history_vector(action)\n",
    "        image.draw_one_box(agent.boundary)\n",
    "        image.add_text(step, (agent.boundary[\"xmin\"], agent.boundary[\"ymin\"]))\n",
    "        if agent.sub_image.shape[0] * agent.sub_image.shape[1] == 0:\n",
    "            done = True\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = agent.get_state()\n",
    "            reward = reward_move(old_iou, iou)\n",
    "            \n",
    "    print(\"current action = {}\".format(int(action)), end=\" || \")\n",
    "    print(\"current reward = {}\".format(float(reward)))\n",
    "    if done:\n",
    "        break\n",
    "image.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = [1,2,3]\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{}log.json\".format(Settings.model_path), \"w\") as f:\n",
    "    json.dump(loss_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
