{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Q Model\n",
    "## Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to load data\n",
      "Start to load images: 1000=>2000=>3000=>4000=>5000=>6000=>7000=>8000=>9000=>10000=>11000=>11540!\n",
      "Start to load annotations: 1000=>2000=>3000=>4000=>5000=>6000=>7000=>8000=>9000=>10000=>11000=>11540!\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "from FileUtils import FileUtils\n",
    "import matplotlib.pyplot as plt \n",
    "data = FileUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter_by_class(\"bird\")\n",
    "total_num = len(data.images) # the length of the cat images\n",
    "total_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import QModel\n",
    "from Settings import Settings\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if Settings.cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model = QModel()\n",
    "target_model = QModel()\n",
    "target_model.load_state_dict(policy_model.state_dict())\n",
    "\n",
    "if Settings.cuda:\n",
    "    policy_model.cuda()\n",
    "    target_model.cuda()\n",
    "target_model = target_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReplayMemory import ReplayMemory\n",
    "memory = ReplayMemory(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(policy_model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from Agent import Agent\n",
    "from IoU import *\n",
    "from TrainUtils import optimize_model\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 100\n",
    "train_num = int(0.8 * total_num)\n",
    "update_num = 3\n",
    "eps = Settings.eps_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 0.25)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Settings.iou_threshold, Settings.gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Model Training\n",
      "Save min loss network\n",
      "Update Network\n",
      "==> Epoch 0 End, time cost = 54.2607, current loss = 2.6791, next eps = 0.8\n",
      "Save min loss network\n",
      "==> Epoch 1 End, time cost = 58.2235, current loss = 1.5933, next eps = 0.7\n",
      "Save min loss network\n",
      "==> Epoch 2 End, time cost = 64.2051, current loss = 0.8984, next eps = 0.6\n",
      "Update Network\n",
      "==> Epoch 3 End, time cost = 69.2652, current loss = 1.3867, next eps = 0.5\n",
      "==> Epoch 4 End, time cost = 75.1861, current loss = 0.9113, next eps = 0.4\n",
      "Update Network\n",
      "==> Epoch 6 End, time cost = 81.1185, current loss = 1.1357, next eps = 0.2\n",
      "Save min loss network\n",
      "==> Epoch 7 End, time cost = 89.653, current loss = 0.8641, next eps = 0.1\n",
      "==> Epoch 8 End, time cost = 92.8349, current loss = 1.2574, next eps = 0.1\n",
      "Save min loss network\n",
      "Update Network\n",
      "==> Epoch 9 End, time cost = 96.5364, current loss = 0.778, next eps = 0.1\n",
      "Save min loss network\n",
      "==> Epoch 10 End, time cost = 93.1028, current loss = 0.751, next eps = 0.1\n",
      "Save min loss network\n",
      "==> Epoch 11 End, time cost = 90.9908, current loss = 0.5853, next eps = 0.1\n",
      "Save min loss network\n",
      "Update Network\n",
      "==> Epoch 12 End, time cost = 95.4258, current loss = 0.4932, next eps = 0.1\n",
      "==> Epoch 13 End, time cost = 93.9955, current loss = 0.5863, next eps = 0.1\n",
      "Save min loss network\n",
      "==> Epoch 14 End, time cost = 94.9099, current loss = 0.4691, next eps = 0.1\n",
      "Save min loss network\n",
      "Update Network\n",
      "==> Epoch 15 End, time cost = 92.1174, current loss = 0.3784, next eps = 0.1\n",
      "==> Epoch 16 End, time cost = 96.5194, current loss = 0.4743, next eps = 0.1\n",
      "Save min loss network\n",
      "==> Epoch 17 End, time cost = 92.7286, current loss = 0.3772, next eps = 0.1\n",
      "Update Network\n",
      "==> Epoch 18 End, time cost = 91.21, current loss = 0.6654, next eps = 0.1\n",
      "==> Epoch 19 End, time cost = 93.4222, current loss = 0.4716, next eps = 0.1\n",
      "==> Epoch 20 End, time cost = 91.9817, current loss = 0.3952, next eps = 0.1\n",
      "Update Network\n",
      "==> Epoch 21 End, time cost = 92.5882, current loss = 0.5135, next eps = 0.1\n",
      "==> Epoch 22 End, time cost = 92.9384, current loss = 0.4707, next eps = 0.1\n",
      "==> Epoch 23 End, time cost = 92.5305, current loss = 0.4071, next eps = 0.1\n",
      "Update Network\n",
      "==> Epoch 24 End, time cost = 90.8926, current loss = 0.5676, next eps = 0.1\n",
      "==> Epoch 25 End, time cost = 93.2788, current loss = 0.4463, next eps = 0.1\n",
      "Update Network\n",
      "==> Epoch 27 End, time cost = 91.2789, current loss = 0.3868, next eps = 0.1\n",
      "==> Epoch 28 End, time cost = 92.4166, current loss = 0.4419, next eps = 0.1\n",
      "==> Epoch 29 End, time cost = 93.8102, current loss = 0.3646, next eps = 0.1\n",
      "Save min loss network\n",
      "Update Network\n",
      "==> Epoch 30 End, time cost = 92.2026, current loss = 0.2637, next eps = 0.1\n",
      "==> Epoch 31 End, time cost = 91.7217, current loss = 0.2944, next eps = 0.1\n",
      "==> Epoch 32 End, time cost = 89.7016, current loss = 0.4777, next eps = 0.1\n",
      "Update Network\n",
      "==> Epoch 33 End, time cost = 94.0336, current loss = 0.338, next eps = 0.1\n",
      "==> Epoch 34 End, time cost = 89.8663, current loss = 0.3701, next eps = 0.1\n",
      "==> Epoch 35 End, time cost = 92.6095, current loss = 0.3637, next eps = 0.1\n",
      "Update Network\n",
      "==> Epoch 36 End, time cost = 92.5427, current loss = 0.3182, next eps = 0.1\n",
      "==> Epoch 37 End, time cost = 92.8411, current loss = 0.3015, next eps = 0.1\n",
      "==> Epoch 38 End, time cost = 92.0054, current loss = 0.3245, next eps = 0.1\n",
      "Update Network\n",
      "==> Epoch 39 End, time cost = 89.3366, current loss = 0.2896, next eps = 0.1\n",
      "==> Epoch 40 End, time cost = 90.8004, current loss = 0.2775, next eps = 0.1\n",
      "==> Epoch 41 End, time cost = 91.7865, current loss = 0.2817, next eps = 0.1\n",
      "Save min loss network\n",
      "Update Network\n",
      "==> Epoch 42 End, time cost = 91.9317, current loss = 0.1808, next eps = 0.1\n",
      "==> Epoch 44 End, time cost = 92.4676, current loss = 0.2444, next eps = 0.1\n",
      "Update Network\n",
      "==> Epoch 45 End, time cost = 92.0973, current loss = 0.4326, next eps = 0.1\n",
      "==> Epoch 46 End, time cost = 91.4389, current loss = 0.3468, next eps = 0.1\n",
      "==> Epoch 47 End, time cost = 91.7733, current loss = 0.3233, next eps = 0.1\n",
      "Update Network\n",
      "==> Epoch 48 End, time cost = 91.44, current loss = 0.4403, next eps = 0.1\n",
      "==> Epoch 49 End, time cost = 90.8343, current loss = 0.2896, next eps = 0.1\n",
      "==> Epoch 50 End, time cost = 90.4798, current loss = 0.3411, next eps = 0.1\n",
      "Update Network\n",
      "==> Epoch 51 End, time cost = 91.2492, current loss = 0.3811, next eps = 0.1\n",
      "==> Epoch 52 End, time cost = 90.5919, current loss = 0.359, next eps = 0.1\n",
      "==> Epoch 53 End, time cost = 90.3105, current loss = 0.2533, next eps = 0.1\n",
      "Update Network\n",
      "==> Epoch 54 End, time cost = 88.8785, current loss = 0.3448, next eps = 0.1\n",
      "==> Epoch 55 End, time cost = 91.9645, current loss = 0.2666, next eps = 0.1\n",
      "==> Epoch 56 End, time cost = 90.5616, current loss = 0.3156, next eps = 0.1\n",
      "Update Network\n",
      "==> Epoch 57 End, time cost = 88.4408, current loss = 0.3406, next eps = 0.1\n",
      "==> Epoch 58 End, time cost = 87.9411, current loss = 0.4077, next eps = 0.1\n",
      "==> Epoch 59 End, time cost = 93.3454, current loss = 0.2818, next eps = 0.1\n",
      "Update Network\n",
      "==> Epoch 60 End, time cost = 91.994, current loss = 0.2431, next eps = 0.1\n",
      "==> Epoch 61 End, time cost = 91.8975, current loss = 0.3013, next eps = 0.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Start Model Training\")\n",
    "loss_list = list()\n",
    "min_loss = float(\"inf\")\n",
    "\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "#     print(\"==> Epoch {} start ...\".format(epoch))\n",
    "    start = time.time()\n",
    "    cur_loss = 0.0\n",
    "    policy_model.train()\n",
    "    \n",
    "    for i, image in enumerate(data.images[:train_num]):\n",
    "        annotation_list = data.annotations[i]\n",
    "        agent = Agent(image)\n",
    "        done = False\n",
    "        old_iou_list = None\n",
    "        \n",
    "        for step in range(Settings.max_step):\n",
    "            iou_list = [iou_calculator(agent.boundary, x) for x in annotation_list]\n",
    "            max_index = max(range(len(iou_list)), key=lambda x: iou_list[x])\n",
    "            iou = max(iou_list)\n",
    "\n",
    "            old_iou = old_iou_list[max_index] if old_iou_list else 0\n",
    "            old_iou_list = iou_list\n",
    "            cur_state = agent.get_state()\n",
    "            \n",
    "            # determine if we should end the result \n",
    "            if iou > Settings.iou_threshold:\n",
    "                action = torch.tensor(6).to(device)\n",
    "            else:\n",
    "                action = agent.get_next_action(policy_model, eps)\n",
    "\n",
    "            if action == 6:\n",
    "                reward = reward_terminal(iou)\n",
    "                agent.update_history_vector(action)\n",
    "                done = True\n",
    "                next_state = None\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                agent.hierarchical_move(action)\n",
    "                agent.update_history_vector(action)\n",
    "                \n",
    "                if agent.sub_image.shape[0] * agent.sub_image.shape[1] == 0:\n",
    "                    done = True\n",
    "                    next_state = None\n",
    "                \n",
    "                else:\n",
    "                    next_state = agent.get_state()\n",
    "                    reward = reward_move(old_iou, iou)\n",
    "            \n",
    "            memory.push(cur_state, action, next_state, reward)\n",
    "            cur_loss = optimize_model(policy_model, target_model, memory, optimizer)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "    \n",
    "    min_loss = min(cur_loss, min_loss)\n",
    "    if min_loss == cur_loss:\n",
    "        print(\"Save min loss network\")\n",
    "        with open(\"{}model_{}.pt\".format(Settings.model_path, epoch), 'wb') as f:\n",
    "            torch.save(policy_model.cpu().state_dict(), f)\n",
    "            if Settings.cuda:\n",
    "                policy_model.cuda()\n",
    "                \n",
    "    if epoch % update_num == 0:\n",
    "        print(\"Update Network\")\n",
    "        target_model.load_state_dict(policy_model.state_dict())\n",
    "        target_model.eval()\n",
    "        loss_list.append(cur_loss)\n",
    "        \n",
    "        # save logs\n",
    "        with open(\"{}log_1.json\".format(Settings.model_path), \"w\") as f:\n",
    "            json.dump(loss_list, f)\n",
    "\n",
    "    if eps > 0.11:\n",
    "        eps -= 0.1\n",
    "    else:\n",
    "        eps = 0.1\n",
    "    \n",
    "    time_cost = time.time() - start\n",
    "    print(\"==> Epoch {} End, time cost = {}, current loss = {}, next eps = {}\".format(epoch, round(time_cost,4), cur_loss, round(eps,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModelOnOneImage(image_index):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data.images[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Image import Image\n",
    "image = Image(data,4)\n",
    "annotation_list = image.objects\n",
    "agent = Agent(image.image)\n",
    "done = False\n",
    "old_iou_list = None\n",
    "\n",
    "for step in range(Settings.max_step):\n",
    "    print(\"Step {}\".format(step), end=\"=>\")\n",
    "    \n",
    "\n",
    "    iou_list = [iou_calculator(agent.boundary, x) for x in annotation_list]\n",
    "    max_index = max(range(len(iou_list)), key=lambda x: iou_list[x])\n",
    "    iou = max(iou_list)\n",
    "    \n",
    "    print(\"current iou = {}\".format(iou), end=\" || \")\n",
    "    old_iou = old_iou_list[max_index] if old_iou_list else 0\n",
    "    old_iou_list = iou_list\n",
    "\n",
    "    cur_state = agent.get_state()\n",
    "\n",
    "    # determine if we should end the result \n",
    "    if iou > Settings.iou_threshold:\n",
    "        action = torch.tensor(6).to(device)\n",
    "    else:\n",
    "        action = agent.get_next_action(target_model, eps=0)\n",
    "\n",
    "    if action == 6:\n",
    "        reward = reward_terminal(iou)\n",
    "        done = True\n",
    "        next_state = None\n",
    "    else:\n",
    "        agent.hierarchical_move(action)\n",
    "        agent.update_history_vector(action)\n",
    "        image.draw_one_box(agent.boundary)\n",
    "        image.add_text(step, (agent.boundary[\"xmin\"], agent.boundary[\"ymin\"]))\n",
    "        if agent.sub_image.shape[0] * agent.sub_image.shape[1] == 0:\n",
    "            done = True\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = agent.get_state()\n",
    "            reward = reward_move(old_iou, iou)\n",
    "            \n",
    "    print(\"current action = {}\".format(int(action)), end=\" || \")\n",
    "    print(\"current reward = {}\".format(float(reward)))\n",
    "    if done:\n",
    "        break\n",
    "image.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
